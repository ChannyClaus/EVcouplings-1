{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running EVcouplings pipeline jobs\n",
    "\n",
    "## Content\n",
    "\n",
    "This notebook demonstrates how to run EVcouplings jobs by specifying the job settings in a configuration file and then executing it using the EVcouplings command line applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration files\n",
    "\n",
    "Config file drives all aspects of the pipeline (which query protein, and which parameters like bitscore thresholds, databases etc.). The config files are in computable YAML format (see below for example how to modify it programmatically).\n",
    "\n",
    "> For an example configuration file, see config/sample_config.txt in this repository.\n",
    "\n",
    "### Parameters that might need to be modified (non-exhaustive):\n",
    "\n",
    "The following parameters are the most important ones to consider modifying when running your job:\n",
    "\n",
    "1) In “global” section:\n",
    "* prefix (includes output folder, anything after last “/” will be prefix of filenames, folders are made automatically), e.g. output/run4/RASH_HUMAN would create subfolders output/run4/ in current directory and then filenames would start with RASH_HUMAN (name can be arbitrary). Good convention e.g. RASH_HUMAN_4-169\n",
    "* sequence_id (Uniprot ID or AC): sequence will be automatically fetched from Uniprot\n",
    "* region: leave blank for full sequence or put [start_pos, stop_pos]\n",
    "\n",
    "2) In \"alignment\" section:\n",
    "* domain_threshold (bitscore or evalue). 0.5 is a good starting point for bitscore, e.g. use 0.3 for more inclusive and 0.7 or 0.8 for less inclusive alignment\n",
    "* sequence_threshold (bitscore or evalue), typically should be same as domain_threshold\n",
    "* iterations: number of jackhmmer iterations\n",
    "* database: uniref, uniprot (see databases section for options or to modify path)\n",
    "* seqid_filter: Filter alignment at x% sequence identity. Leave empty or set to 100 not to filter any sequences.\n",
    "* minimum_sequence_coverage (formerly called \"-f\" in buildali)\n",
    "* minimum_column_coverage (formerly called \"-m\" in buildali, but now the other way round: -m 30 corresponds to minimum_column_coverage=70)\n",
    "\n",
    "3) in \"couplings\" section:\n",
    "* theta (note that this is 1 - theta is used so far in pipelines, e.g. this pipeline uses 0.8 rather than 0.2 to cluster at 80% sequence identity)\n",
    "* iterations: how many plmc iterations to run\n",
    "* ignore_gaps: exclude gaps from EC calculation\n",
    "* save_model: save binary file with model parameters or not\n",
    "\n",
    "4) in \"compare\" section:\n",
    "\n",
    "* by_alignment: If True, structures for comparison will be identified by homology search; otherwise use only structures for given sequence_id (must be UniProt ID or AC)\n",
    "* pdb_ids: Used if by_alignment is False. If pdb_ids is None, compares to all PDB structures for given sequence_id. If list of PDB IDs, compare to that subset of structures only.\n",
    "* compare_multimer: Besides intra-chain contacts, also identify homomultimer contacts and use in evaluation.\n",
    "* distance_cutoff: Maximum distance for a residue pair to be considered as a contact\n",
    "* min_sequence_distance: Only use pairs that are at least this distant in sequence for evaluation\n",
    "\n",
    "### Configuration rules\n",
    "\n",
    "Configuration files are handled internally according to the following rules:\n",
    "\n",
    "1) Global settings override settings of the same name for stages\n",
    "\n",
    "2) Outputs of a stage are merged into \"global\" and fed into input of subsequent stages. This allows results to be passed on from stage to stage.\n",
    "\n",
    "3) All settings are explicitly specified in the configuration. No hidden defaults in code.\n",
    "\n",
    "4) Each stage is also passed the databases and tools sections\n",
    "\n",
    "\n",
    "### Batch jobs\n",
    "\n",
    "By specifying the \"batch\" section in the config file, one can easily generate multiple jobs:\n",
    "\n",
    "    batch:\n",
    "        _b0.75:\n",
    "           align: {domain_threshold: 0.75, sequence_threshold: 0.75}\n",
    "        _b0.3:\n",
    "           align: {domain_threshold: 0.3, sequence_threshold: 0.3}\n",
    "\n",
    "This example will create two jobs, which extend the global job prefix by _b0.75 and _b0.3, and replace the settings in  the \"align\" section with the given values. All other configuration settings will be constant for the job.\n",
    "\n",
    "To execute batch jobs, the *evcouplings* application has to be used (see below for details, not possible using *evcouplings_runcfg*).\n",
    "\n",
    "### Modifying the config file from within Python:\n",
    "\n",
    "The configuration files used by EVcouplings are standard YAML files that directly translate to standard data structures such as lists and dictionaries. This means that configuration files can be easily loaded, modified programmatically (e.g. when running large amounts of jobs), and stored to file again.\n",
    "\n",
    "Also, the output state after running a pipeline is stored in YAML files, which means the results can be easily accessed and passed on to other code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from evcouplings.utils import read_config_file, write_config_file\n",
    "\n",
    "config = read_config_file(\"../config/sample_config.txt\", preserve_order=True)\n",
    "config[\"global\"][\"prefix\"] = \"output/RASH_HUMAN\"\n",
    "config[\"global\"][\"sequence_id\"] = \"RASH_HUMAN\"\n",
    "config[\"align\"][\"domain_threshold\"] = 0.5\n",
    "\n",
    "write_config_file(\"test_config.txt\", config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the pipeline\n",
    "\n",
    "EVcouplings provides three ways of executing configuration files. The applications *evcouplings_runcfg* and *evcouplings* will be created automatically and put on your PATH when installing the Python package (i.e. they should be available from any directory):\n",
    "\n",
    "### evcouplings_runcfg\n",
    "\n",
    "Execute a single configuration file (this will ignore the \"batch\" section and runs a *single* thread of the pipeline):\n",
    "\n",
    "```bash\n",
    "evcouplings_runcfg <config_file>\n",
    "```\n",
    "\n",
    "If running in a batch computing environment, the user is responsible for submitting jobs etc.\n",
    "\n",
    "### evcouplings\n",
    "\n",
    "This is a wrapper around *evcouplings_runcfg* which provides the three major additional functions:\n",
    "* for convenience, overwrite parameters in a config file using command line flags (e.g. to simply change proteins or specify a list of E-value thresholds)\n",
    "* execute batch jobs (e.g. for scanning different evolutionary depths)\n",
    "* submit to batch computing environments to parallelize jobs, and create summary statistics and visualizations of results\n",
    "\n",
    "Running evcouplings requires to specify the \"environment\" section in the configuration file. Currently, we only support local execution using multithreading, and LSF. If you need another environment (e.g. SGE, Torque or Slurm), please consider implementing it and submit a pull request!\n",
    "\n",
    "For a list of the available command line arguments, please run\n",
    "\n",
    "```bash\n",
    "evcouplings --help\n",
    "```\n",
    "\n",
    "To run a config file, execute:\n",
    "\n",
    "```bash\n",
    "evcouplings_runcfg [options] <config_file>\n",
    "```\n",
    "\n",
    "Example of overriding the settings in the config file to run different bitscore thresholds of a protein (this will create 6 independent jobs for each bitscore):\n",
    "\n",
    "```bash\n",
    "evcouplings_runcfg -P output/RASH_HUMAN -p RASH_HUMAN -b \"0.1, 0.2, 0.3, 0.4, 0.5, 0.6\" sample_config.txt\n",
    "```\n",
    "\n",
    "### Running pipeline from within Python\n",
    "\n",
    "Configuration files can also be directly run from within Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from evcouplings.utils import read_config_file\n",
    "from evcouplings.utils.pipeline import execute\n",
    "\n",
    "config = read_config_file(\"test_config.txt\")\n",
    "outcfg = execute(**config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [python3]",
   "language": "python",
   "name": "Python [python3]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
